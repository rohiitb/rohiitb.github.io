<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Rohit Bhikule</title>
  
  <meta name="author" content="Rohit Bhikule">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/upenn_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:43%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rohit Bhikule</name>
              </p>
              <p> I'm a graduate student at University of Pennsylvania</a>. I'm currently working on <a href="https://www.dcist.org/">DCIST</a> (a project focusing on multi-agent and heterogeneous systems) in <a href="https://www.kumarrobotics.org/">Kumar Lab</a>, which's a subgroup of GRASP.<br><br>
              My research interest lies in Multi-agent system, Micro Unmanned Aerial Vehicles (UAV), Robot Perception and Learning.
              </p>
              <p style="text-align:center">
                <a href="mailto:rbhikulej@seas.upenn.edu">Email</a> &nbsp/&nbsp
                <a href="data/ZDD_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/rohiitb">github</a> &nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:80%;max-width:80%">
              <a href="images/profile_pic.jpg"><img style="width:100%;max-width:150%" alt="profile photo" src="images/profile_pic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        
        
        <br><br><br>
        
        <!-- Projects start here !-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <heading>Projects</heading>
              </td>
            </tr>
          </tbody>
        </table>
        
        
        <table style="width:130%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
          <!--         Mask-RCNN -->

                   <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"> 
                     <td style="padding:20px;width:30%;vertical-align:middle">
                      <div class="one">
                          <img src='images/mh1.png' width="200" height="200">
                      </div>
                       
                       <script type="text/javascript">
                         function nerf_start() {
                           document.getElementById('nerf_image').style.opacity = "1";
                         }

                         function nerf_stop() {
                           document.getElementById('nerf_image').style.opacity = "0";
                         }
                         nerf_stop()
                       </script>
                     </td>
                     
                     
                     <td style="padding:20px;width:75%;vertical-align:middle">
                       <papertitle>
                         Instance Segmentation : Mask-RCNN 
                        </papertitle>
                       <br>
                 <em>Fall 2022</em>
                       <br>                       
                      <a href="https://github.com/rohiitb/MaskRCNN">Github</a>
                       <p></p>
                       <p>
                       In this project, Mask-RCNN object detection and instance segmentation pipeline is implemented and tested on COCO dataset consisting of 3 object classes - Animals, Vehicles and People.
                       <br>
                       <br>
                       Mask RCNN is a a conceptually simple, flexible, and general framework for object instance segmentation.It extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. This pipeline was implemented to do per pixel object detection and the corresponding mask.
                       <br>
                       </p>
                     </td>
                   </tr>
            

          <!-- Quadrotor -->

          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  
            <td style="padding:20px;width:30%;vertical-align:middle">
             <div class="one">
                 <img src='images/crazyflie.gif' width="200" height="210">
             </div>

              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>
                  Quadrotor Planning and Control 
                </papertitle>
              <br>
        <em>Spring 2022</em>
              <br>
              <a href="data/quad_controller.pdf"> Project page</a> /

              <a href="data/proj_report.pdf"> Report</a> /
              
              <a href="https://youtu.be/W0gOJvOaMI8"> Video</a> /
        
              <a href="https://github.com/rohiitb/Quadrotor_planning_and_control"> Github</a>
              <p></p>
              <p> In this project, we implemented Geometric non-linear controller algorithm to control a
                  quadrotor which could follow a predefined trajectory and reach the goal without collision in an obstacle cluttered environment. 
                  The optimal trajectory was obtained by down-sampling the waypoints to the shortest path which was
                  generated by A*, followed by trajectory smoothening.
                <br>
                  We also fused the IMU and stereo pair information to get the 3D pose of the quadrotor using Error State Kalman Filter (Visual Inertial Odometry). 
                <br>
                  This project focused on demonstrating the planning aspect of robot capabilities. During the lab, the
                  CrazyFlie 2.0 was used for realistic demonstrations. A
                  microcomputer is responsible for low-level control and
                  estimation, while the onboard IMU provides feedback
                  of angular velocities and accelerations. The attitude
                  and thrust commands are sent to the quadrotor via the
                  CrazyRadio after being computed in python.
                  <br>
              </p>
            </td>
          </tr> 

          
          <!-- F1 tenth -->

<!--          <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/race.gif' width="220" height="220">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://f1tenth.org/">
                <papertitle>F1tenth Racing (UPenn ESE 615 Autonomous Racing)</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/shivangimisra1/">Shivangi Misra</a>,
              <strong>Dingding Zheng</strong>,
              <a href="https://weiyi-tang.netlify.app/">Weiyi Tang</a>
              <br>
              <em>Spring</em> 2020
              <br>
              <a href="https://f1tenth.org/">project page</a> /
              
              <a href="data/ESE_615_Final_Report_by_Team_1.pdf">report</a>/

              <a href="https://github.com/zddkjmuner/Autonomous-Racing">code</a>
              <p></p>
              <p><a href="https://f1tenth.org/build.html">”F1tenth”</a> is an open-source, small-scale racing car platform
                widely used for teaching and research in safe autonomy.
                Maneuvering a racing car to finish loops in minimum time
                has been studied for decades. However, it’s always computationally
                expensive and infeasible to solve this problem by
                real-time trajectory planning. In this project, we generated
                a velocity profile to find the maximum permissible speed of
                racing car on each waypoint on the path. Then, we use CMAES
                (Covariance Matrix Adaptation - Evolution Strategy) to
                generate the desired path for vehicle to track. The generated
                path has a relatively small curvature which allows the racing
                car to run at high, steady speed. Pure pursuit is used as
                the vehicle controller. To avoid obstacles, we implemented
                ODG-PFM (Obstacle-Dependent Gaussian Potential
                Field) and compared its performance VS. RRT*. In order to
                measure the performance of these two algorithms, we setup
                several testing maps and added noise to the environment.
              </p>
            </td>
          </tr>    -->

  
          <!-- SLAM -->
  
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/map1.PNG' width="200" height="200">
                        </div>
                        <script type="text/javascript">
                          function nerf_start() {
                            document.getElementById('nerf_image').style.opacity = "1";
                          }

                          function nerf_stop() {
                            document.getElementById('nerf_image').style.opacity = "0";
                          }
                          nerf_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Simultaneous Localization and Mapping (SLAM)
                          </papertitle>
                        <br>
                      <em>Spring 2022</em>
                        <br>
                        <a href="https://github.com/rohiitb/MonteCarlo_localization_SLAM">Github</a>
                        <p></p>
                        <p>
                            This project shows an approach for mapping a scene while localizing the robot using a 2D laser scan. 
                            Here we integrated the IMU orientation and odometry information from a walking humanoid robot in order to build a 2D occupancy grid map of the walls and obstacles in the environment. 
                            Then additional camera and depth imagery from a Kinect sensor were integrated to build a textured map.
                            <br><br><br>
                        </p>
                      </td>
                    </tr>
          
          
          <!-- MPC Manipulator Arm -->
  
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/mpc_gif.gif' width="200" height="200">
                        </div>
                        <script type="text/javascript">
                          function nerf_start() {
                            document.getElementById('nerf_image').style.opacity = "1";
                          }

                          function nerf_stop() {
                            document.getElementById('nerf_image').style.opacity = "0";
                          }
                          nerf_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>7DoF Robotic Arm Manipulation using MPC and Vision-based Object gripping
                          </papertitle>
                        <br>
                      <em>Fall 2022</em>
                        <br>
                        <a href="https://github.com/rohiitb/manipulator_mpc">Github</a>
                        <p></p>
                        <p>
                            This project shows an approach for mapping a scene while localizing the robot using a 2D laser scan. 
                            Here we integrated the IMU orientation and odometry information from a walking humanoid robot in order to build a 2D occupancy grid map of the walls and obstacles in the environment. 
                            Then additional camera and depth imagery from a Kinect sensor were integrated to build a textured map.
                            <br><br><br>
                        </p>
                      </td>
                    </tr>

          
          <!-- UKF -->
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
            <td style="padding:20px;width:25%;vertical-align:middle">
             <div class="one">
               <img src='images/res1.png' width="270" height="200">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Orienation Tracking using Unscented Kalman Filter</papertitle>
              <br>
                <em>Spring 2022</em>
                <br>
              <a href="https://github.com/rohiitb/Orientation_tracking_using_UKF">Github</a>
              <p></p>
              <p>
                  In this project, we implemented a kalman filter to track three dimensional orientation. 
                  Given IMU sensor readings from gyroscopes and accelerometers, we estimated the underlying 3D orientation by learning the appropriate model parameters from ground truth data given by a Vicon motion capture system.
              </p>
            </td>
          </tr>

          
          
          <!-- YOLO -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/yolo.JPG' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>YOLO (Object Detection)</papertitle>
              <br>
                <em>Fall</em> 2022
              <br>
                <a href="https://github.com/rohiitb/YOLO">Github</a>
              <p></p>
              <p>Implemented YOLO pipeline from scratch to do object detection on street scene images. <br>MAP acheived : 0.43</p>
            </td>
          </tr>
          
          <!-- SOLO -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/first1.png' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>SOLO (Instance Segmentation)</papertitle>
              <br>
                <em>Fall</em> 2022
              <br>
                <a href="https://github.com/rohiitb/SOLO_Instance_segmentation">Github</a>
              <p></p>
              <p>Implemented a single-stage instance segmentation pipeline "Segmenting Objects by Location" based on Feature pyramid network model to classify and generate masks for objects belonging to 3 categories: Animals, Vehicles and Humans.</p>
            </td>
          </tr>
          
          

            <!-- 3D Reconstruction from images -->
            <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
              <td style="padding:30px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/recon_gif.gif' width="200" height="160">
                </div>
                <script type="text/javascript">
                  function dpzlearn_start() {
                    document.getElementById('dpzlearn_image').style.opacity = "1";
                  }

                  function dpzlearn_stop() {
                    document.getElementById('dpzlearn_image').style.opacity = "0";
                  }
                  dpzlearn_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
            
                  <papertitle>3D Reconstruction from images </papertitle>
                <br>
                    <em>Spring 2022</em>
                <br>
                <a href="data/hw6-580-2019.pdf">project page</a> /
              <a href="https://github.com/rohiitb/Two_view_stereo_3D_reconstruction">code</a>
                <br>
                <p>
                In this project, we were given an image of oilcan to tain a heatmap-based neural network which estimates the location of the keypoints in that image. Each 2D heatmap corresponded to one keypoint and was responsible to localize this particular keypoint in the image. During training, we synthesized the heatmaps by identifying the location of each keypoint on the 2D image and placing a 2D Gaussian centered on this location on the corresponding heatmap. Then, we used the coordinates of detected keypoints to estimate the 6DoF pose of the object.
                </p>
              </td>
            </tr>



          <!-- Penn logo -->
<!--           <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td style="padding:30px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/logo.gif' width="200" height="160">
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }

                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Logo Projection </papertitle>
              <br>
              <em>Spring</em> 2019
              <br>
              <p>Estimated the homography that maps the video images onto the logo points, then warped the sampled points according to the homography. Used this correspondence to project the "Penn Engineering" logo to the goal in a football match.</p>
            </td>
          </tr> -->
          
          <!-- Autonomous Battle Bot -->
          <tr onmouseout="loss_stop()" onmouseover="loss_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/pic2.jpg' width="200" height="200">
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }

                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Autonomous Battle Bot</papertitle>
              <br>
              <em>Fall</em> 2021
              <br>
              <a href="https://github.com/rohiitb/Autonomous_Battle_bot">code</a>
              <p></p>
              <p>
                Designed and fabricated a 2-wheel differential drive robot with a gripper arm capable of grabbing cans and also detect light of desired frequencies.<br>
                Robot was also capable of navigating itself to a particular location using VIVE localization system.<br>
                ESP32 microcontroller was used for controlling and grabbing.<br>
                Wireless communication via HTML(Webpage) and UDP was used to send commands to the robot.
              </p>
            </td>
          </tr>







        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                    Great thanks to Jon for his amazing <a href="https://jonbarron.info/">website template</a>!

              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>


<!--Great thanks to Jon for his amazing <a href="https://jonbarron.info/">website template</a>!-->
</body>

</html>
